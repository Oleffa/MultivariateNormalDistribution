{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultivariateNormalDistribution import mvn\n",
    "\n",
    "import itertools\n",
    "\n",
    "from scipy import linalg\n",
    "from sklearn import mixture\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn import utils\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import math\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm.html\n",
    "color_iter = itertools.cycle(['r', 'g', 'b', 'y',\n",
    "                              'black'])\n",
    "\n",
    "def plot_results(X, Y_, means, covariances, index, title):\n",
    "    splot = plt.subplot(2, 1, 1 + index)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        # as the DP will not use every component it has access to\n",
    "        # unless it needs it, we shouldn't plot the redundant\n",
    "        # components.\n",
    "        if not np.any(Y_ == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], 2, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "\n",
    "    #plt.xlim(-9., 5.)\n",
    "    #plt.ylim(-3., 6.)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)\n",
    "    \n",
    "def show_internal_number_representation(mvn):\n",
    "    # Displays the internal representation that the MVN has of the learned number by reshaping\n",
    "    # the learned mu and plotting it\n",
    "    # Works only with digits datasets or other 8x8 data\n",
    "    plt.figure(1, figsize=(3, 3))\n",
    "    plt.imshow(mvn.mu.reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOutcome(data, y, mvn_list, dimensions):\n",
    "    out = []\n",
    "    for i in range(0,len(data)):\n",
    "        cur = np.transpose(data[i].reshape(1,dimensions))\n",
    "        logliks = []\n",
    "        for mvn in mvn_list:\n",
    "            #if mvn.isInitialized:\n",
    "            logliks.append(mvn.logPosteriorPredictive(cur))\n",
    "            #else:\n",
    "                #logliks.append(-10000000000)  \n",
    "        #print(\"predicted: {}, acutal: {}\".format(logliks.index(max(logliks)), y[i]))\n",
    "        out.append(logliks.index(max(logliks)))\n",
    "    #print(\"===done===\")\n",
    "    return out\n",
    "def concatenate_all(input_list, axis=0):\n",
    "    out = input_list[0]\n",
    "    for i in range(1,len(input_list)):\n",
    "        out = np.concatenate((out, input_list[i]),axis=axis)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "#=======DEBUG===========\n",
    "prior_data_size = 10\n",
    "test_data_size = 15\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data # Features \n",
    "y = digits.target # Targets\n",
    "target_number = len(set(y)) # Number of different targets\n",
    "\n",
    "\n",
    "dimensions = np.shape(X[1])[0] # Dimension is number of features (64 in the case of digits dataset)\n",
    "dataset_size = len(digits.target) # Determine the dataset size and calculate the size of the training data\n",
    "# Generate training and test data for first type of iris\n",
    "\n",
    "# Only take part of the dimensions\n",
    "X = X[:,range(0,dimensions)]\n",
    "print(\"===================== prepare data ================================\")\n",
    "# Lists for training data\n",
    "X_training = []\n",
    "y_training = []\n",
    "# Lists for test data\n",
    "X_testing = []\n",
    "y_testing = []\n",
    "# Lists for mvn related variables\n",
    "priors = []\n",
    "mvns = []\n",
    "training_data_size = []\n",
    "for i in range(0,target_number):\n",
    "    # Get all datasets from the same class\n",
    "    X_type_1 = X[y==i]\n",
    "    y_type_1 = y[y==i]\n",
    "    # Prepare prior dataset\n",
    "    X_type_1_prior = np.transpose((X_type_1[range(0,prior_data_size)]))\n",
    "    # Prepare training dataset\n",
    "    X_type_1_train = np.transpose(X_type_1[range(prior_data_size,len(X_type_1)-test_data_size),:])\n",
    "    X_training.append(np.transpose(X_type_1_train))\n",
    "    y_type_1_train = np.transpose(y_type_1[range(prior_data_size,len(X_type_1)-test_data_size)])\n",
    "    y_training.append(y_type_1_train)\n",
    "    # Prepare test dataset\n",
    "    X_type_1_test = np.transpose(X_type_1[range(len(X_type_1)-test_data_size,len(X_type_1)),:])\n",
    "    X_testing.append(np.transpose(X_type_1_test))\n",
    "    y_type_1_test = y_type_1[range(len(X_type_1)-test_data_size,len(X_type_1))]\n",
    "    y_testing.append(y_type_1_test)\n",
    "    # Calculate prior for the mvn\n",
    "    mvn_prior_1 = mvn.MultivariateNormalDistribution(dimensions=dimensions, name=\"prior1\")\n",
    "    mvn_prior_1.MLE(X_type_1_prior)\n",
    "    priors.append(mvn_prior_1)\n",
    "    # Create the MVN with prior\n",
    "    nu0 = dimensions+2;\n",
    "    S_0 = np.multiply(np.diag(np.diag(mvn_prior_1.sigma)),nu0)\n",
    "    m_0 = mvn_prior_1.mu\n",
    "    kappa0 = prior_data_size\n",
    "    mvn_type_1 = mvn.MultivariateNormalDistribution(dimensions=dimensions, m0=m_0, S0=S_0 , kappa=kappa0, nu=nu0, name=\"MVN1\")\n",
    "    mvns.append(mvn_type_1)\n",
    "    # Build a list that contains the number of samples per class\n",
    "    training_data_size.append(len(np.transpose(X_type_1_train)))\n",
    "\n",
    "print(\"===================== learn ================================\")\n",
    "# Prepare training data from all classes\n",
    "X_training = concatenate_all(X_training)\n",
    "y_training = concatenate_all(y_training)\n",
    "X_testing = concatenate_all(X_testing)\n",
    "y_testing = concatenate_all(y_testing)\n",
    "\n",
    "# X_train, y_train = utils.shuffle(X_train,y_train)\n",
    "\n",
    "print(np.shape(X_training))\n",
    "print(np.shape(y_training))\n",
    "print(np.shape(X_testing))\n",
    "print(np.shape(y_testing))\n",
    "\n",
    "\n",
    "for j in range(0,len(X_training)):\n",
    "    for i in range(0, target_number):\n",
    "        if y_training[j] == i:\n",
    "            X_train = np.transpose(X_training[i])\n",
    "            mvns[i].MAP(X_training[j].reshape((dimensions,1)))\n",
    "            # Measure performance\n",
    "            y_pred = predictOutcome(X_testing, y_testing,mvns, dimensions)\n",
    "            f1 = metrics.f1_score(y_testing, y_pred, average=None)\n",
    "            print(f1)\n",
    "\n",
    "show_internal_number_representation(mvns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- There are still errors with lambda, in the setter when updating sigma the linalg gives a singular matrix error\n",
    "- Test shuffle training data after everything works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirichlet",
   "language": "python",
   "name": "dirichlet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
