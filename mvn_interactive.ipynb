{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultivariateNormalDistribution import mvn\n",
    "\n",
    "import itertools\n",
    "\n",
    "from scipy import linalg\n",
    "from sklearn import mixture\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn import utils\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import math\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm.html\n",
    "color_iter = itertools.cycle(['r', 'g', 'b', 'y',\n",
    "                              'black'])\n",
    "\n",
    "def plot_results(X, Y_, means, covariances, index, title):\n",
    "    splot = plt.subplot(2, 1, 1 + index)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        # as the DP will not use every component it has access to\n",
    "        # unless it needs it, we shouldn't plot the redundant\n",
    "        # components.\n",
    "        if not np.any(Y_ == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], 2, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "\n",
    "    #plt.xlim(-9., 5.)\n",
    "    #plt.ylim(-3., 6.)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dimensions = 4\n",
    "prior_data_size = 5\n",
    "training_data_size = 45\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # Features\n",
    "y = iris.target # Targets\n",
    "# Only take part of the dimensions\n",
    "X = X[:,range(0,dimensions)]\n",
    "# Shuffle dataset\n",
    "X, y = utils.shuffle(X,y)\n",
    "\n",
    "\n",
    "\n",
    "# Generate training and test data for first type of iris\n",
    "X_type_1 = X[y==0]\n",
    "y_type_1 = y[y==0]\n",
    "X_type_1_prior = np.transpose(X_type_1[range(0,prior_data_size)])\n",
    "X_type_1_train = np.transpose(X_type_1[range(prior_data_size,training_data_size),:])\n",
    "X_type_1_test = np.transpose(X_type_1[range(training_data_size,50),:])\n",
    "\n",
    "\n",
    "X_type_2 = X[y==1]\n",
    "y_type_2 = y[y==1]\n",
    "X_type_2_prior = np.transpose(X_type_2[range(0,prior_data_size)])\n",
    "X_type_2_train = np.transpose(X_type_2[range(prior_data_size,training_data_size),:])\n",
    "X_type_2_test = np.transpose(X_type_2[range(training_data_size,50),:])\n",
    "\n",
    "X_type_3 = X[y==2]\n",
    "y_type_3 = y[y==2]\n",
    "X_type_3_prior = np.transpose(X_type_3[range(0,prior_data_size)])\n",
    "X_type_3_train = np.transpose(X_type_3[range(prior_data_size,training_data_size),:])\n",
    "X_type_3_test = np.transpose(X_type_3[range(training_data_size,50),:])\n",
    "\n",
    "# Generate randomized training data\n",
    "#X_train = np.concatenate((X_type_1_train, X_type_2_train, X_type_3_train),axis=0)\n",
    "# Generate randomized test data\n",
    "print(\"===================== reference ================================\")\n",
    "mvn_ref = mvn.MultivariateNormalDistribution(dimensions=dimensions, name=\"reference\")\n",
    "mvn_ref.MLE(np.transpose(X_type_1))\n",
    "print(\"reference mu: \\n{}\".format(mvn_ref.mu))\n",
    "\n",
    "\n",
    "print(\"===================== prior 1 ================================\")\n",
    "mvn_prior = mvn.MultivariateNormalDistribution(dimensions=dimensions, name=\"prior\")\n",
    "mvn_prior.MLE(X_type_1_prior)\n",
    "print(\"mu prior: \\n{}\".format(mvn_prior.mu))\n",
    "\n",
    "nu0 = prior_data_size # Weight of S_0\n",
    "S_0 = np.multiply(np.diag(np.diag(mvn_prior.sigma)),nu0) # Prior mean for Sigma\n",
    "m_0 = mvn_prior.mu # Prior mean for mu\n",
    "kappa0 = prior_data_size # Weight of m_0\n",
    "print(\"===================== mvn 1 ================================\")\n",
    "mvn_1 = mvn.MultivariateNormalDistribution(dimensions=dimensions, m0=m_0, S0=S_0,kappa=kappa0, nu=nu0, name=\"MVN1\")\n",
    "# Incremental Learning\n",
    "logliks = []\n",
    "liks = []\n",
    "for i in range(0,training_data_size-prior_data_size):\n",
    "    cur_training_data = np.transpose(X_type_1_train)[0]\n",
    "    #print(\"training_data: \\n{}\".format(cur_training_data.reshape(4,1)))\n",
    "    mvn_1.MAP(cur_training_data.reshape(4,1))\n",
    "    #print(mvn_1.mu)\n",
    "    lik1 = mvn_1.likelihood(X_type_1_test)\n",
    "    loglik1 = mvn_1.loglikelihood(X_type_1_test)\n",
    "    print(\"lik1: {}\".format(loglik1))\n",
    "    logliks.append(loglik1)\n",
    "    liks.append(lik1)\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title(\"Log likelihoods\")\n",
    "plt.xlabel(\"Datasets Learned\")\n",
    "plt.ylabel(\"Loglikelihood\")\n",
    "plt.plot(range(0,len(logliks)),logliks)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Likelihoods\")\n",
    "plt.xlabel(\"Datasets Learned\")\n",
    "plt.ylabel(\"Likelihood\")\n",
    "plt.plot(range(0,len(liks)),liks)\n",
    "\n",
    "#learn \n",
    "#f1 score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOutcome(data, y, mvn_list):\n",
    "    out = []\n",
    "    for i in range(0,len(data)):\n",
    "        cur = np.transpose(data[i].reshape(1,4))\n",
    "        logliks = []\n",
    "        for mvn in mvn_list:\n",
    "            #if mvn.isInitialized:\n",
    "            logliks.append(mvn.logPosteriorPredictive(cur))\n",
    "            #else:\n",
    "                #logliks.append(-10000000000)  \n",
    "        #print(\"predicted: {}, acutal: {}\".format(logliks.index(max(logliks)), y[i]))\n",
    "        out.append(logliks.index(max(logliks)))\n",
    "    #print(\"===done===\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dimensions = 4\n",
    "prior_data_size = 6\n",
    "training_data_size = 40\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # Features \n",
    "y = iris.target # Targets\n",
    "# Only take part of the dimensions\n",
    "X = X[:,range(0,dimensions)]\n",
    "\n",
    "# Generate training and test data for first type of iris\n",
    "X_type_1 = X[y==0]\n",
    "y_type_1 = y[y==0]\n",
    "X_type_1_prior = np.transpose(X_type_1[range(0,prior_data_size)])\n",
    "print(X_type_1_prior)\n",
    "X_type_1_train = np.transpose(X_type_1[range(prior_data_size,training_data_size),:])\n",
    "X_type_1_test = np.transpose(X_type_1[range(training_data_size,50),:])\n",
    "y_type_1_test = y_type_1[range(training_data_size,50)]\n",
    "# Generate training and test data for first type of iris\n",
    "X_type_2 = X[y==1]\n",
    "y_type_2 = y[y==1]\n",
    "X_type_2_prior = np.transpose(X_type_2[range(0,prior_data_size)])\n",
    "X_type_2_train = np.transpose(X_type_2[range(prior_data_size,training_data_size),:])\n",
    "X_type_2_test = np.transpose(X_type_2[range(training_data_size,50),:])\n",
    "y_type_2_test = y_type_2[range(training_data_size,50)]\n",
    "# Generate training and test data for first type of iris\n",
    "X_type_3 = X[y==2]\n",
    "y_type_3 = y[y==2]\n",
    "X_type_3_prior = np.transpose(X_type_3[range(0,prior_data_size)])\n",
    "X_type_3_train = np.transpose(X_type_3[range(prior_data_size,training_data_size),:])\n",
    "X_type_3_test = np.transpose(X_type_3[range(training_data_size,50),:])\n",
    "y_type_3_test = y_type_3[range(training_data_size,50)]\n",
    "print(\"===================== prior 1 ================================\")\n",
    "mvn_prior_1 = mvn.MultivariateNormalDistribution(dimensions=dimensions, name=\"prior1\")\n",
    "mvn_prior_1.MLE(X_type_1_prior)\n",
    "print(\"mu prior 1: \\n{}\".format(mvn_prior_1.mu))\n",
    "print(\"===================== prior 2 ================================\")\n",
    "mvn_prior_2 = mvn.MultivariateNormalDistribution(dimensions=dimensions, name=\"prior2\")\n",
    "mvn_prior_2.MLE(X_type_2_prior)\n",
    "print(\"mu prior 2: \\n{}\".format(mvn_prior_2.mu))\n",
    "print(\"===================== prior 3 ================================\")\n",
    "mvn_prior_3 = mvn.MultivariateNormalDistribution(dimensions=dimensions, name=\"prior3\")\n",
    "mvn_prior_3.MLE(X_type_3_prior)\n",
    "print(\"mu prior 3: \\n{}\".format(mvn_prior_3.mu))\n",
    "\n",
    "print(\"===================== mvn 1-3 with prior ================================\")\n",
    "nu0 = dimensions+2;\n",
    "# Check diag, some problem with calculating S_0 in mvtshfhdfahjdf\n",
    "S_0 = np.identity(4)#np.multiply(np.diag(np.diag(mvn_prior_1.sigma)),nu0)\n",
    "m_0 = np.zeros((4,1))#mvn_prior_1.mu\n",
    "kappa0 = 0.01#prior_data_size\n",
    "mvn_type_1 = mvn.MultivariateNormalDistribution(dimensions=dimensions, m0=m_0, S0=S_0 , kappa=kappa0, nu=nu0, name=\"MVN1\")\n",
    "S_0 = np.identity(4)#np.multiply(np.diag(np.diag(mvn_prior_2.sigma)),nu0)\n",
    "m_0 = np.zeros((4,1))#mvn_prior_2.mu\n",
    "kappa0 = 0.01#prior_data_size\n",
    "mvn_type_2 = mvn.MultivariateNormalDistribution(dimensions=dimensions, m0=m_0, S0=S_0 , kappa=kappa0, nu=nu0, name=\"MVN2\")\n",
    "S_0 = np.identity(4)#np.multiply(np.diag(np.diag(mvn_prior_3.sigma)),nu0)\n",
    "m_0 = np.zeros((4,1))#mvn_prior_3.mu\n",
    "kappa0 = 0.01#prior_data_size\n",
    "mvn_type_3 = mvn.MultivariateNormalDistribution(dimensions=dimensions, m0=m_0, S0=S_0 , kappa=kappa0, nu=nu0, name=\"MVN3\")\n",
    "\n",
    "print(\"===================== Interactive Learning ================================\")\n",
    "\n",
    "X_train = np.concatenate((np.transpose(X_type_1_train),np.transpose(X_type_2_train),np.transpose(X_type_3_train)),axis=0)\n",
    "X_test = np.concatenate((np.transpose(X_type_1_test),np.transpose(X_type_2_test),np.transpose(X_type_3_test)),axis=0)\n",
    "y_train = np.concatenate((y_type_1[range(prior_data_size,training_data_size)],y_type_2[range(prior_data_size,training_data_size)],y_type_3[range(prior_data_size,training_data_size)]),axis=0)\n",
    "y_test = np.concatenate((y_type_1_test, y_type_2_test, y_type_3_test),axis=0)\n",
    "\n",
    "X_train, y_train = utils.shuffle(X_train,y_train)\n",
    "\n",
    "# Incrementally learn the 3 mvns and Calculate f1 score by using the test \n",
    "# set to see which y_tests are correct and which are not\n",
    "f1_1 = []\n",
    "f1_2 = []\n",
    "f1_3 = []\n",
    "f1_list = []\n",
    "for i in range(0,len(X_train)):\n",
    "    if y_train[i] == 0:\n",
    "        mvn_type_1.MAP(np.transpose(X_train[i].reshape(1,4)))\n",
    "    elif y_train[i] == 1:\n",
    "        mvn_type_2.MAP(np.transpose(X_train[i].reshape(1,4)))\n",
    "    elif y_train[i] == 2:\n",
    "        mvn_type_3.MAP(np.transpose(X_train[i].reshape(1,4)))\n",
    "    # Test and calculate f1 scores\n",
    "    y_pred = predictOutcome(X_test, y_test,[mvn_type_1,mvn_type_2,mvn_type_3])\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average=None)\n",
    "    f1_1.append(f1[0])\n",
    "    f1_2.append(f1[1])\n",
    "    f1_3.append(f1[2])\n",
    "    f1_list.append(metrics.f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "x_tick = range(0,len(f1_1))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(111)\n",
    "plt.title(\"F1 scores\")\n",
    "plt.xlabel(\"Datasets Learned\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.plot(x_tick,f1_1)\n",
    "plt.plot(x_tick,f1_2)\n",
    "plt.plot(x_tick,f1_3)\n",
    "plt.plot(x_tick,f1_list,color='m')\n",
    "\n",
    "# plot ellipsoids for all dimensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirichlet",
   "language": "python",
   "name": "dirichlet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
